{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae40d43e",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0b4f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c970ca",
   "metadata": {},
   "source": [
    "Task 1: Sentiment Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54081687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject    0.0\n",
      "body       0.0\n",
      "date       0.0\n",
      "from       0.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2191/2191 [00:01<00:00, 2184.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "Neutral     1053\n",
      "Positive     974\n",
      "Negative     164\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_csv('./data/raw/test.csv')\n",
    "print(df.isna().mean().sort_values(ascending=False))\n",
    "df = df.fillna('') \n",
    "\n",
    "#combine subject and body into a single text column\n",
    "df['text'] = df.apply(lambda row: row['body'] if row['body'].strip() else row['Subject'], axis=1)\n",
    "df = df[df['text'].str.strip() != '']\n",
    "\n",
    "#label sentiment\n",
    "def classify_sentiment(text):\n",
    "    polarity = TextBlob(text).sentiment.polarity\n",
    "    if polarity > 0.1:\n",
    "        return 'Positive'\n",
    "    elif polarity < -0.1:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "tqdm.pandas()\n",
    "df['Sentiment'] = df['text'].progress_apply(classify_sentiment)\n",
    "\n",
    "#save labeled data\n",
    "os.makedirs('./data/processed', exist_ok=True)\n",
    "df.to_csv('./data/processed/labeled_messages.csv', index=False)\n",
    "\n",
    "print(df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660fcad8",
   "metadata": {},
   "source": [
    "Task 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "083312ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 2191\n",
      "Date parsing success rate: 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_parsed</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             missing_ratio\n",
       "Subject                0.0\n",
       "body                   0.0\n",
       "date                   0.0\n",
       "from                   0.0\n",
       "text                   0.0\n",
       "Sentiment              0.0\n",
       "date_parsed            0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2191, 7)\n",
      "\n",
      "Columns:\n",
      " Index(['Subject', 'body', 'date', 'from', 'text', 'Sentiment', 'date_parsed'], dtype='object')\n",
      "\n",
      "Data types:\n",
      " Subject                object\n",
      "body                   object\n",
      "date                   object\n",
      "from                   object\n",
      "text                   object\n",
      "Sentiment              object\n",
      "date_parsed    datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "Missing ratio per column:\n",
      "              missing_ratio\n",
      "Subject                0.0\n",
      "body                   0.0\n",
      "date                   0.0\n",
      "from                   0.0\n",
      "text                   0.0\n",
      "Sentiment              0.0\n",
      "date_parsed            0.0\n",
      "Sentiment\n",
      "Neutral     1053\n",
      "Positive     974\n",
      "Negative     164\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentiment distribution (normalized):\n",
      " Sentiment\n",
      "Neutral     0.480602\n",
      "Positive    0.444546\n",
      "Negative    0.074852\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Monthly sentiment trend:\n",
      " Sentiment  Negative  Neutral  Positive\n",
      "month                                 \n",
      "2011-01           4       47        40\n",
      "2011-02           8       45        38\n",
      "2011-03          11       38        43\n",
      "2011-04           6       41        45\n",
      "2011-05           8       41        43\n",
      "2011-06           3       41        47\n",
      "2011-07           5       41        45\n",
      "2011-08           3       47        41\n",
      "2011-09           2       39        50\n",
      "2011-10           9       38        44\n",
      "2011-11           6       41        45\n",
      "2011-12           7       48        37\n",
      "\n",
      "Top 10 employees by message count:\n",
      " from\n",
      "lydia.delgado@enron.com        284\n",
      "john.arnold@enron.com          256\n",
      "sally.beck@enron.com           227\n",
      "patti.thompson@enron.com       225\n",
      "bobette.riner@ipgdirect.com    217\n",
      "don.baughman@enron.com         213\n",
      "johnny.palmer@enron.com        213\n",
      "eric.bass@enron.com            210\n",
      "kayne.coulter@enron.com        174\n",
      "rhonda.denton@enron.com        172\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Employees with most negative messages:\n",
      " from\n",
      "lydia.delgado@enron.com        20\n",
      "patti.thompson@enron.com       19\n",
      "john.arnold@enron.com          19\n",
      "bobette.riner@ipgdirect.com    19\n",
      "rhonda.denton@enron.com        17\n",
      "sally.beck@enron.com           16\n",
      "johnny.palmer@enron.com        15\n",
      "kayne.coulter@enron.com        15\n",
      "eric.bass@enron.com            15\n",
      "don.baughman@enron.com          9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "\n",
    "# Paths\n",
    "RAW_DIR = Path(\"./data/raw\")\n",
    "PROC_DIR = Path(\"./data/processed\")\n",
    "VIZ_DIR = Path(\"./visualization\")\n",
    "VIZ_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "#load saved data\n",
    "df = pd.read_csv(PROC_DIR / \"labeled_messages.csv\")\n",
    "print(\"Rows:\", len(df))\n",
    "df.head()\n",
    "\n",
    "#date cleaning & parsing\n",
    "def clean_date(x):\n",
    "    \"\"\"Convert '########' or empty strings to NaT, else parse M/D/YYYY.\"\"\"\n",
    "    if isinstance(x, str) and x.strip().startswith(\"#\"):\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        return pd.to_datetime(x, format=\"%m/%d/%Y\", errors=\"coerce\")\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "df[\"date_parsed\"] = df[\"date\"].apply(clean_date)\n",
    "#save\n",
    "df.to_csv(PROC_DIR / \"labeled_messages.csv\", index=False)\n",
    "\n",
    "print(\"Date parsing success rate:\", df[\"date_parsed\"].notna().mean())\n",
    "missing_summary = df.isna().mean().rename(\"missing_ratio\").to_frame()\n",
    "display(missing_summary)\n",
    "\n",
    "#sentiment distribution\n",
    "sns.countplot(x=\"Sentiment\", data=df, order=[\"Positive\", \"Neutral\", \"Negative\"])\n",
    "plt.title(\"Sentiment Distribution\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(VIZ_DIR / \"sentiment_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "#time series sentiment trend\n",
    "df_time = (\n",
    "    df.dropna(subset=[\"date_parsed\"])\n",
    "      .assign(month=lambda d: d[\"date_parsed\"].dt.to_period(\"M\"))\n",
    "      .groupby([\"month\", \"Sentiment\"])\n",
    "      .size()\n",
    "      .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "df_time.plot(kind=\"bar\", stacked=False)\n",
    "plt.title(\"Monthly Message Count by Sentiment\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(VIZ_DIR / \"monthly_sentiment_counts.png\")\n",
    "plt.close()\n",
    "\n",
    "#top senders by message volume\n",
    "top_senders = (\n",
    "    df.groupby(\"from\")[\"text\"].count().sort_values(ascending=False).head(10)\n",
    ")\n",
    "sns.barplot(y=top_senders.index, x=top_senders.values, orient=\"h\")\n",
    "plt.title(\"Top 10 Employees by # Messages\")\n",
    "plt.xlabel(\"Message Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(VIZ_DIR / \"top_senders.png\")\n",
    "plt.close()\n",
    "\n",
    "#data summary:\n",
    "# Shape and column names\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\\n\", df.columns)\n",
    "\n",
    "# Data types\n",
    "print(\"\\nData types:\\n\", df.dtypes)\n",
    "\n",
    "# Missing value ratio\n",
    "missing_summary = df.isna().mean().rename(\"missing_ratio\").to_frame()\n",
    "print(\"\\nMissing ratio per column:\\n\", missing_summary)\n",
    "\n",
    "# Distribution of sentiment values\n",
    "print(df['Sentiment'].value_counts())\n",
    "print(\"\\nSentiment distribution (normalized):\\n\", df['Sentiment'].value_counts(normalize=True))\n",
    "\n",
    "# Drop NA dates and convert to month\n",
    "df_time = (\n",
    "    df.dropna(subset=[\"date_parsed\"])\n",
    "      .assign(month=lambda d: d[\"date_parsed\"].dt.to_period(\"M\"))\n",
    "      .groupby([\"month\", \"Sentiment\"])\n",
    "      .size()\n",
    "      .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "print(\"\\nMonthly sentiment trend:\\n\", df_time.tail(12))  # last 12 months, for brevity\n",
    "\n",
    "# Who sends the most messages?\n",
    "top_senders = df['from'].value_counts().head(10)\n",
    "print(\"\\nTop 10 employees by message count:\\n\", top_senders)\n",
    "\n",
    "# Check if any senders only send negative messages\n",
    "only_negative = df[df[\"Sentiment\"] == \"Negative\"][\"from\"].value_counts()\n",
    "print(\"\\nEmployees with most negative messages:\\n\", only_negative.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f7b3ad",
   "metadata": {},
   "source": [
    "Task 3: Employee Score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8f1a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Employee    Month  Score\n",
      "0  bobette.riner@ipgdirect.com  2010-01      2\n",
      "1  bobette.riner@ipgdirect.com  2010-02      7\n",
      "2  bobette.riner@ipgdirect.com  2010-03      4\n",
      "3  bobette.riner@ipgdirect.com  2010-04      2\n",
      "4  bobette.riner@ipgdirect.com  2010-05      1\n"
     ]
    }
   ],
   "source": [
    "# üìç 2. Load Labeled Data\n",
    "df = pd.read_csv(\"./data/processed/labeled_messages.csv\")\n",
    "def clean_date(x):\n",
    "    \"\"\"Convert '########' or empty strings to NaT, else parse M/D/YYYY.\"\"\"\n",
    "    if isinstance(x, str) and x.strip().startswith(\"#\"):\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        return pd.to_datetime(x, format=\"%m/%d/%Y\", errors=\"coerce\")\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "df[\"date_parsed\"] = df[\"date\"].apply(clean_date)\n",
    "#save parsed date column\n",
    "df.to_csv(\"./data/processed/labeled_messages.csv\", index=False)\n",
    "df = df.dropna(subset=[\"date_parsed\"])  # Drop rows without date\n",
    "\n",
    "#map scores\n",
    "sentiment_map = {\"Positive\": 1, \"Negative\": -1, \"Neutral\": 0}\n",
    "df[\"Sentiment_Score\"] = df[\"Sentiment\"].map(sentiment_map)\n",
    "\n",
    "df[\"YearMonth\"] = df[\"date_parsed\"].dt.to_period(\"M\")\n",
    "\n",
    "#combine monthly scores\n",
    "monthly_scores = (\n",
    "    df.groupby([\"from\", \"YearMonth\"])[\"Sentiment_Score\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"from\": \"Employee\", \"YearMonth\": \"Month\", \"Sentiment_Score\": \"Score\"})\n",
    ")\n",
    "\n",
    "#save data\n",
    "print(monthly_scores.head())\n",
    "monthly_scores.to_csv(\"./data/processed/monthly_sentiment_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e85517",
   "metadata": {},
   "source": [
    "Task 4: Employee ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e86a8244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Employee    Month  Score     Rank_Type\n",
      "0      kayne.coulter@enron.com  2010-01      5  Top Positive\n",
      "1     patti.thompson@enron.com  2010-01      5  Top Positive\n",
      "2       don.baughman@enron.com  2010-01      4  Top Positive\n",
      "3      rhonda.denton@enron.com  2010-01      0  Top Negative\n",
      "4      johnny.palmer@enron.com  2010-01      1  Top Negative\n",
      "5  bobette.riner@ipgdirect.com  2010-01      2  Top Negative\n",
      "6  bobette.riner@ipgdirect.com  2010-02      7  Top Positive\n",
      "7        john.arnold@enron.com  2010-02      7  Top Positive\n",
      "8       don.baughman@enron.com  2010-02      6  Top Positive\n",
      "9      lydia.delgado@enron.com  2010-02      1  Top Negative\n",
      "                      Employee  Overall_Score   Global_Rank\n",
      "6      lydia.delgado@enron.com              5  Top Positive\n",
      "3        john.arnold@enron.com              4  Top Positive\n",
      "2          eric.bass@enron.com              2  Top Positive\n",
      "8      rhonda.denton@enron.com             -7  Top Negative\n",
      "4      johnny.palmer@enron.com             -4  Top Negative\n",
      "0  bobette.riner@ipgdirect.com             -3  Top Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9588\\2807542822.py:22: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  rankings = df.groupby(\"Month\", group_keys=False).apply(get_rankings).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# üìç 2. Load Monthly Scores\n",
    "df = pd.read_csv(\"./data/processed/monthly_sentiment_scores.csv\")\n",
    "df[\"Month\"] = pd.PeriodIndex(df[\"Month\"], freq=\"M\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üìç 3. Define Ranking Logic\n",
    "def get_rankings(group):\n",
    "    top = (\n",
    "        group.sort_values(by=[\"Score\", \"Employee\"], ascending=[False, True])\n",
    "             .head(3)\n",
    "             .assign(Rank_Type=\"Top Positive\")\n",
    "    )\n",
    "    bottom = (\n",
    "        group.sort_values(by=[\"Score\", \"Employee\"], ascending=[True, True])\n",
    "             .head(3)\n",
    "             .assign(Rank_Type=\"Top Negative\")\n",
    "    )\n",
    "    return pd.concat([top, bottom])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üìç 4. Apply Ranking Per Month\n",
    "rankings = df.groupby(\"Month\", group_keys=False).apply(get_rankings).reset_index(drop=True)\n",
    "\n",
    "# Preview\n",
    "print(rankings.head(10))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üìç 5. Save Rankings to File\n",
    "rankings.to_csv(\"./data/processed/monthly_employee_rankings.csv\", index=False)\n",
    "\n",
    "#get overall top positive and negative employees\n",
    "rankings = pd.read_csv(\"./data/processed/monthly_employee_rankings.csv\")\n",
    "\n",
    "# Assign +1 for Top Positive, ‚Äë1 for Top Negative\n",
    "rankings[\"point\"] = rankings[\"Rank_Type\"].map({\"Top Positive\": 1, \"Top Negative\": -1})\n",
    "\n",
    "# Aggregate points across all months\n",
    "overall_scores = (\n",
    "    rankings.groupby(\"Employee\")[\"point\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"point\": \"Overall_Score\"})\n",
    ")\n",
    "\n",
    "# Sort for global Top Positive (highest) and Top Negative (lowest)\n",
    "top_global_positive = (\n",
    "    overall_scores.sort_values(by=[\"Overall_Score\", \"Employee\"], ascending=[False, True])\n",
    "    .head(3)\n",
    "    .assign(Global_Rank=\"Top Positive\")\n",
    ")\n",
    "\n",
    "top_global_negative = (\n",
    "    overall_scores.sort_values(by=[\"Overall_Score\", \"Employee\"], ascending=[True, True])\n",
    "    .head(3)\n",
    "    .assign(Global_Rank=\"Top Negative\")\n",
    ")\n",
    "\n",
    "global_top3 = pd.concat([top_global_positive, top_global_negative])\n",
    "print(global_top3)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üìç 7. Save Global Rankings\n",
    "global_top3.to_csv(\"./data/processed/global_top3_employees.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ced81a7",
   "metadata": {},
   "source": [
    "Task 5: Flight Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b777d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Employee  At_Risk\n",
      "0  bobette.riner@ipgdirect.com     True\n",
      "3        john.arnold@enron.com     True\n",
      "4      johnny.palmer@enron.com     True\n",
      "6      lydia.delgado@enron.com     True\n",
      "7     patti.thompson@enron.com     True\n",
      "8      rhonda.denton@enron.com     True\n",
      "9         sally.beck@enron.com     True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9588\\3268918470.py:26: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  risk_flags = df_neg.groupby(\"from\").apply(flag_risk).reset_index()\n"
     ]
    }
   ],
   "source": [
    "#read data\n",
    "df = pd.read_csv(\"./data/processed/labeled_messages.csv\")\n",
    "df[\"date_parsed\"] = pd.to_datetime(df[\"date_parsed\"], errors=\"coerce\")\n",
    "\n",
    "# Keep only negative messages with a valid date\n",
    "df_neg = df[(df[\"Sentiment\"] == \"Negative\") & (df[\"date_parsed\"].notna())]\n",
    "df_neg = df_neg.sort_values([\"from\", \"date_parsed\"])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üìç 3. Identify Rolling 30-day Negative Message Clusters\n",
    "def flag_risk(group):\n",
    "    risk_dates = []\n",
    "    dates = group[\"date_parsed\"].tolist()\n",
    "    for i in range(len(dates)):\n",
    "        count = 1\n",
    "        start = dates[i]\n",
    "        for j in range(i+1, len(dates)):\n",
    "            if (dates[j] - start).days <= 30:\n",
    "                count += 1\n",
    "            else:\n",
    "                break\n",
    "        if count >= 4:\n",
    "            risk_dates.append(start)\n",
    "    return pd.Series({\"At_Risk\": len(risk_dates) > 0})\n",
    "\n",
    "risk_flags = df_neg.groupby(\"from\").apply(flag_risk).reset_index()\n",
    "risk_flags = risk_flags.rename(columns={\"from\": \"Employee\"})\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üìç 4. Output & Save\n",
    "print(risk_flags[risk_flags[\"At_Risk\"] == True])\n",
    "risk_flags.to_csv(\"./data/processed/flight_risk_employees.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15e758d",
   "metadata": {},
   "source": [
    "Task 6: Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "054a75fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.42765020804350784\n",
      "RMSE: 1.994649338696962\n",
      "          Feature  Coefficient\n",
      "0       msg_count     0.347254\n",
      "1  avg_msg_length    -0.004865\n",
      "2  avg_word_count     0.039418\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# load and preprocess data\n",
    "df = pd.read_csv(\"./data/processed/labeled_messages.csv\")\n",
    "df[\"date_parsed\"] = pd.to_datetime(df[\"date_parsed\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"date_parsed\"])\n",
    "\n",
    "# Sentiment to numeric\n",
    "sentiment_map = {\"Positive\": 1, \"Negative\": -1, \"Neutral\": 0}\n",
    "df[\"Sentiment_Score\"] = df[\"Sentiment\"].map(sentiment_map)\n",
    "\n",
    "# Message features\n",
    "df[\"char_count\"] = df[\"text\"].astype(str).apply(len)\n",
    "df[\"word_count\"] = df[\"text\"].astype(str).apply(lambda x: len(x.split()))\n",
    "df[\"Month\"] = df[\"date_parsed\"].dt.to_period(\"M\")\n",
    "\n",
    "# Group & Feature Engineering\n",
    "monthly_df = df.groupby([\"from\", \"Month\"]).agg({\n",
    "    \"text\": \"count\",\n",
    "    \"char_count\": \"mean\",\n",
    "    \"word_count\": \"mean\",\n",
    "    \"Sentiment_Score\": \"sum\"\n",
    "}).reset_index()\n",
    "\n",
    "monthly_df = monthly_df.rename(columns={\n",
    "    \"from\": \"Employee\",\n",
    "    \"text\": \"msg_count\",\n",
    "    \"char_count\": \"avg_msg_length\",\n",
    "    \"word_count\": \"avg_word_count\",\n",
    "    \"Sentiment_Score\": \"sentiment_score\"\n",
    "})\n",
    "\n",
    "# Train/Test Split\n",
    "features = [\"msg_count\", \"avg_msg_length\", \"avg_word_count\"]\n",
    "X = monthly_df[features]\n",
    "y = monthly_df[\"sentiment_score\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Evaluation\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "# Coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Feature\": features,\n",
    "    \"Coefficient\": model.coef_\n",
    "})\n",
    "print(coef_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
